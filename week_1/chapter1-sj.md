# 예상 질문
### 질문 1. 가상머신과 컨테이너의 차이는 무엇이고, 컨테이너의 장점과 한계는 무엇인가? (p. 49)

- **가상머신**
    - 구조
        - Host OS 위에 하이퍼바이저가 있고, 그 위에 Guest OS를 포함하고 있는 가상머신이 올라간다.
        - 따라서 각각의 가상머신은 완전히 분리된 운영체제를 갖고 동작한다.
    - 실행 흐름
        - 가상 머신에서 실행 중인 어플리케이션이 특정 OS 작업을 필요로 할때 (예: 파일 읽기, 네트워크 통신 등) 시스템 콜을 하면, 해당 시스템 콜 명령을 게스트 OS가 받는다.
        - 게스트 OS 커널은 실제로는 가상화된 환경에서 동작하고 있기 때문에, 직접 물리적 CPU에 접근할 수 없다.
        - 따라서 게스트 OS 커널은 해당 시스템콜 명령을 하이퍼바이저에 전달한다. 하이퍼바이저는 이 요청을 받아서 실제 물리적 CPU에서 해당 x86 명령을 실행한다. (Type1 하이퍼바이저일 경우에 한함. 만약 Type2 하이퍼바이저일 경우 Host OS에 맞는 명령어로 전환하여 Host OS에 전달한다. )
    - 장점
        - 강력한 격리성 : Guest OS가 독립적으로 동작하여 높은 수준의 보안을 제공한다.
        - OS 유연성 : Host OS와 상관 없이 Guest OS 선택이 가능함. 예를 들어 Host OS가 윈도우여도 Guest OS로 리눅스를 선택할 수 있다.
    - 단점
        - 어플리케이션 뿐만 아니라 Guest OS를 기동시킬 만큼의 추가 리소스가 필요하므로 무겁다.
- **컨테이너**
    - 구조
        - Host OS 위에 바로 컨테이너가 기동되며, 그럼에도 리눅스 컨테이너 격리 기술을 이용하기 때문에 각 컨테이너는 독립된 환경에서 실행되는 것과 동일한 효과를 갖는다.
    - 실행 흐름
        - 호스트 OS에서 실행되는 동일한 커널에서 시스템 콜을 수행한다.
        - 컨테이너 안의 프로세스가 시스템 콜을 요청하면 이 요청이 호스트 OS의 커널로 직접 전달된다.
        - 커널은 이 요청이 어느 컨테이너에서 왔는지 확인하고 해당 컨테이너의 제한 사항과 권한을 검사한 뒤, 허용된 범위 내에서 요청을 처리한다.
    - 장점
        - VM보다 훨씬 가볍고 빠르게 실행되고 리소스 사용이 효율적이다.. (게스트OS가 필요 없고, 명령어 변환 과정 필요 없이 바로 호스트 OS로 전달되므로)
    - 단점
        - 호스트 OS와 다른 종류의 커널은 사용할 수 없다.(예: 윈도우 호스트에서 리눅스 컨테이너 직접 실행 불가)
        - 만약 애플리케이션이 특정 버전의 커널 명령어를 필요로 하는 경우, 호스트 OS가 같은 종류의 커널이더라도 실행이 안될 수 있다.
    

### 질문2. 쿠버네티스에서 주요 컴포넌트와 그 역할은 무엇인가? (p.62 ~ 63)

<img width="969" alt="image" src="https://github.com/user-attachments/assets/b714a2ca-ad07-4416-abe2-4373af4313f0" />

- **컨트롤 프레인**
    - 쿠버네티스 API 서버 : 사용자, 컨트롤 플레인 구성 요소와 통신한다.
    - 스케줄러 : 애플리케이션의 배포를 담당한다. (애플리케이션의 배포 가능한 각 구성 요소를 워커 노드에 할당)
    - 컨트롤러 매니저 : 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등과 같은 클러스터단의 기능을 수행한다.
    - Etcd : 클러스터 구성을 지속적으로 저장하는 신뢰할 수 있는 분산 데이터 저장소
- **노드**
    - 컨테이너 런타임 : 컨테이너를 실행하는 도커 혹은 rkt 또는 다른 컨테이너 런타임
    - Kubelet : API 서버와 통신하고 노드의 컨테이너를 관리
    - kube-proxy : 애플리케이션 구성 요소 간에 네트워크 트래픽을 로드밸런싱
- **실행 흐름 (p.99)**
    - 이미지 빌드 → 도커 허브에 푸시
    - kubectl 명령어 실행 → API 서버로 Rest Http 요청 → 클러스터에 새로운 레플리케이션 컨트롤러 오브젝트 생성 → 스케쥴러에 의해 워커 노드 중 하나에 스케줄링 됨
    - 해당 워커 노드의 kubelet은 파드가 스케줄링 됐다는 것을 보고 이미지가 로컬에 없기 때문에 도커에게 레지스트리에서 특정 이미지를 풀하도록 지시. 이미지 다운로드 후 도커는 컨테이너를 생성하고 실행


# 궁금한 점
## 1. 가상머신의 실행 흐름 (p. 49)

<img width="427" alt="image" src="https://github.com/user-attachments/assets/e734ff1a-0cf5-401b-8d38-d09ffb8698b4" />

<img width="530" alt="image" src="https://github.com/user-attachments/assets/e6c6c952-d645-4253-ac72-05adcd2b3108" />

호스트에 가상머신 세 개를 실행하면 세 개의 완전히 분리된 운영체제가 실행되고 동일한 베어메탈 하드웨어를 공유하게 된다. 이런 가상머신 아래에는 물리적 하드웨어 리소스를 각 가상 머신 내부의 운영체제에서 사용할 수 있는 더 작은 리소스로 나누는 호스트 OS와 하이퍼바이저가 있다. 해당 가상머신 내에서 실행되는 애플리케이션이 가상머신의 게스트 OS 커널에 대한 시스템 콜을 수행하면, 커널은 하이퍼바이저로 호스트의 물리적 CPU에서 x86 명령을 수행한다.

---

### 1) 위 과정을 좀 더 상세하게 설명하면?

<aside>
💡

- 가상머신 안에서 애플리케이션이 실행 중입니다
- 이 애플리케이션이 뭔가 작업을 하려면 (예: 파일 읽기, 네트워크 통신 등) 시스템 콜을 합니다
- 이 시스템 콜은 가상머신의 게스트 OS 커널로 전달됩니다
- 게스트 OS 커널은 실제로는 가상화된 환경에서 동작하고 있기 때문에, 직접 물리적 CPU에 접근할 수 없습니다
- 따라서 커널은 하이퍼바이저에게 "이 명령을 실행해줘"라고 요청합니다
- 하이퍼바이저는 이 요청을 받아서 실제 물리적 CPU에서 해당 x86 명령을 실행합니다
</aside>

### 2) 만약 베어메탈 머신 CPU가 x86이 아니라 ARM일 때, 하이퍼바이저는 VM으로부터 받은 시스템콜 명령을 ARM CPU에 맞게 변환해주는건가?

<aside>
💡

네, 정확히 이해하셨습니다. 하이퍼바이저의 중요한 역할 중 하나가 바로 그것입니다.

하이퍼바이저는 두 가지 방식으로 이를 처리할 수 있습니다:

1. Type 1 하이퍼바이저(네이티브/베어메탈 하이퍼바이저)의 경우:
- VM이 ARM CPU용으로 컴파일된 게스트 OS를 실행 중이라면:
    - 직접 ARM 명령어를 물리적 CPU로 전달
    - 성능이 가장 좋음
- VM이 x86용 게스트 OS를 실행 중이라면:
    - x86 명령어를 ARM 명령어로 변환해야 함
    - 이 과정에서 성능 저하 발생
1. Type 2 하이퍼바이저(호스트 OS 위에서 실행)의 경우:
- 호스트 OS → 하이퍼바이저 → 게스트 OS 순으로 명령어 변환
- 추가적인 오버헤드 발생

실제 운영 환경에서는 보통:

- ARM 서버라면 ARM용 게스트 OS를 사용
- x86 서버라면 x86용 게스트 OS를 사용

이렇게 호스트 CPU와 동일한 아키텍처의 게스트 OS를 사용하는 것이 성능상 가장 유리합니다.

</aside>
