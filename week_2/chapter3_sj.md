## 1. Pod란?

- **파드가 필요한 이유?**
    - 컨테이너는 단일 프로세스를 실행하는 것을 목적으로 설계했다.
        - 단일 컨테이너에서 관련 없는 다른 프로세스를 실행하는 경우 모든 프로세스를 실행하고 로그를 관리하는 것은 모두 사용자 책임이 됨
        - 예) 개별 프로세스가 실패하는 경우 자동으로 재시작하는 매커니즘을 포함해야 함. 또한 이러한 모든 프로세스는 동일한 표준 출력으로 로그를 기록하기 때문에 어떤 프로세스가 난ㅁ긴 로그인지 파악하는 것이 어렵다.
    - 여러 프로세스를 단일 컨테이너로 묶지 않기 때문에, 컨테이너를 함께 묶고 하나의 단위로 관리할 수 있는 또 다른 상위 구조가 필요하다.

- **동일 파드에서 컨테이너간에 공유되는 부분과 격리되는 부분**
    - **공유되는 부분**
        - **동일한 리눅스 네임스페이스를 공유**
            - 파드의 모든 컨테이너는 동일한 **네트워크 네임스페이스, UTS 네임스페이스** 안에서 실행됨 
            → 모든 컨테이너는 같은 호스트 이름과 네트워크 인터페이스를 공유한다.
            - 파드의 모든 컨테이너는 **동일한 IPC 네임스페이스** 아래에서 실행돼 IPC를 통해 서로 통신할 수 있다.
        - **동일한 IP와 포트 공간을 공유**
            - 파드 안의 컨테이너가 **동일한 네트워크 네임스페이스**에서 실행되기 때문에, 동일한 IP 주소와 포트 공간을 공유함.
            - 따라서 동일한 파드 안 컨테이너에서 실행 중인 프로세스가 같은 포트 번호를 사용하지 않도록 주의
            - 파드 안에 있는 모든 컨테이너는 동일한 루프백 네트워크 인터페이스를 가짐 → 컨테이너들이 로컬 호스트를 통해 서로 통신할 수 있음
    - **격리되는 부분**
        - 파일 시스템
        - 대부분의 컨테이너 파일시스템은 컨테이너 이미지에서 나오기 때문에, 기본적으로 파일시스템은 다른 컨테이너와 완전히 분리된다.
        - 그러나 쿠버네티스의 볼륨을 이용해 컨테이너가 파일 디렉터리를 공유하는 것이 가능함.

- **파드 간 플랫 네트워크**
  <img width="620" alt="image" src="https://github.com/user-attachments/assets/d0852ec1-ce8c-46cb-acc7-100804048619" />

    - 각 파드는 고유의 IP를 가짐.
    - 모든 파드는 다른 pod의 IP 주소를 사용해 접근하는 것이 가능함. 둘 사이에는 어떠한 NAT (Network Address Translation)도 존재하지 않는다.
        - 쿠버네티스 클러스터의 모든 파드는 하나의 Flat한 공유 네트워크 주소 공간에 상주하기 때문
    - 두 파드가 서로 네트워크 패킷을 보내면, 상대방의 실제 IP 주소를 패킷 안에 있는 출발지 IP 주소에서 찾을 수 있다.
    - 이는 일반적으로 물리 네트워크 위에 추가적인 소프트웨어 정의 네트워크 계층을 통해 달성됨.
    - 덧) 단, 파드는 일시적이기 때문에 파드가 삭제되었다가 레플리케이션 컨트롤러에 의해 새로운 pod로 대체되면, 새로운 파드는 다른 IP 주소를 할당 받음 
    → 따라서 클라이언트는 서버 파드에 직접 연결하는 대신 서비스의 IP 주소를 통해 연결해야 함. 서비스는 어떠 파드가 어떤 IP를 갖는지에 관계없이 파드 중 하나로 연결해 요청을 처리하도록 함.

## 2. 쿠버네티스 로깅 아키텍처와 통합 모니터링의 로그 수집 정책

p. 115

> 각 컨테이너는 격리된 머신과 비슷하기 때문에 여러 프로세스를 단일 컨테이너 안에서 실행하는 것이 타당하다고 생각할 수 있지만 실제로는 그렇지 않다.
> 
> 
> **컨테이너는 단일 프로세스를 실행하는 것을 목적으로 설계했다**(프로세스가 자기 자신의 자식 프로세스를 생성하는 것을 제외하면). **단일 컨테이너에서 관련 없는 다른 프로세스를 실행하는 경우 모든 프로세스를 실행하고 로그를 관리하는 것은 모두 사용자 책임이다.** 일례로 개별 프로세스가 실패하는 경우 자동으로 재시작하는 메커니즘을 포함해야 한다. 또한 이러한 **모든 프로세스는 동일한 표준 출력으로 로그를 기록하기 때문에 어떤 프로세스가 남긴 로그인지 파악하는 것이 매우 어렵다.** 
> 
> 따라서 각 프로세스를 자체의 개별 컨테이너로 실행해야 한다. 
> 

### 1) 컨테이너 로그 위치와 관리
<img width="620" alt="image" src="https://github.com/user-attachments/assets/dc45d6f0-d2c1-46f3-bc89-161c33dcc69b" />

- 컨테이너가 실행되면, 애플리케이션이 표준 출력(stdout) 또는 표준 에러(stderr)로 로그를 출력함.
- **컨테이너 런타임**은 표준 출력과 표준 에러 스트림을 호스트 노드의 특정 경로에 있는 로그 파일로 redirects 함.
    - 로그는 `/var/log/pods/{namespace}_{pod-name}_{pod-uid}/{container-name}/0.log` 같은 경로에 저장됨.
    - 컨테이너 파일 시스템이 재시작되거나 삭제되더라도, 로그는 노드에 남아있음
- 이 로그 파일은 **kubelet**이 관리하며, 용량이 너무 커지면 (설정된 정책에 따라) **로그 로테이션을 수행**함.
- 로그 로테이션
    - kubelet이 로그를 자동으로 로테이트하도록 설정할 수 있다.
        - 예) `log-size-max=10MB`로 설정되어 있다면, 한 로그 파일이 10MB를 넘으면 kubelet이 새 로그 파일을 만들어 기존 로그를 보관함.
        - 일반적으로 오래된 로그 파일은 `.log.1`, `.log.2`와 같이 번호가 붙어 보관됨.
        - 로그 로테이션 예시
            
            ```jsx
            /var/log/pods/default_nginx-1234_abcd/nginx/0.log
            /var/log/pods/default_nginx-1234_abcd/nginx/0.log.1
            /var/log/pods/default_nginx-1234_abcd/nginx/0.log.2
            ```
            
    - [kubelet 설정 파일](https://kubernetes.io/ko/docs/tasks/administer-cluster/kubelet-config-file/)을 사용하여 두 개의 kubelet 파라미터 [`containerLogMaxSize` 및 `containerLogMaxFiles`](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/#kubelet-config-k8s-io-v1beta1-KubeletConfiguration)를 설정 가능하다.
- 로그 로테이션이 설정되면, kubelet은 컨테이너 런타임과 **CRI(Container Runtime Interface)** 를 통해 통신하며 로그를 정리함
    1. **kubelet이 로그를 모니터링** → 크기가 설정된 용량을 초과하면 로테이션 수행
    2. **kubelet이 CRI를 통해 컨테이너 런타임에 정보 전달** → "이제 새로운 로그 파일을 생성하라"
    3. **컨테이너 런타임이 새로운 로그 파일을 지정된 경로에 생성** → 기존 로그는 `.log.1`, `.log.2`로 백업됨
    - 참고) **CRI는 kubelet과 컨테이너 런타임(Docker, containerd, CRI-O 등) 사이의 표준 API 역할을 함.** 즉, kubelet이 직접 컨테이너 로그를 관리하는 게 아니라, CRI를 통해 **컨테이너 런타임에게 "이제 로그를 이렇게 관리해라"라고 요청하는 방식**
- kubelet이 컨테이너 런타임에 로그 관리 요청을 하면, 런타임이 지정된 파일(`0.log`)에 계속해서 로그를 저장

- 참고) kubelet과 컨테이너 런타임이 로그를 기록하는 방법은 노드의 운영체제에 따라 다르다.
    - 리눅스 시스템에서는 보통 로그를 저장하는 두 가지 방식 존재
        
        1. **systemd-journald (저널링 시스템 로그)**
            - systemd를 사용하는 리눅스 시스템에서는 `journald`라는 서비스가 실행되면서 로그를 관리함.
            - 일반적으로 `journalctl` 명령어를 사용해서 로그를 조회할 수 있음.
            - 예를 들어, `sudo journalctl -u kubelet`을 실행하면 kubelet 서비스의 로그를 확인할 수 있음.
        2. **파일 기반 로깅 (`/var/log/` 경로에 파일로 저장)**
            - 일부 애플리케이션들은 systemd-journald를 사용하지 않고, 자체적으로 `/var/log/` 아래 특정 파일에 로그를 기록함.
            - 예를 들어, `nginx` 같은 애플리케이션은 `/var/log/nginx/access.log` 같은 경로에 로그를 기록함.
        
        하지만 쿠버네티스의 주요 컴포넌트 (API 서버, 컨트롤러 매니저, 스케쥴러)는 파드로 실행되고, 독립적인 시스템 서비스로 실행될 수 있음. **파드로 실행되는 경우, systemd의 journald를 사용하지 않고 `/var/log/` 아래 별도의 로그 파일을 기록함.**
        
        즉, systemd의 journal 로그(`journalctl` 명령어로 확인하는 로그)에 저장되지 않기 때문에, `journalctl`을 사용해 로그를 확인할 수 없음.
        
        대신, 이 컴포넌트들은 **호스트 노드의 `/var/log/` 아래에 로그 파일을 직접 저장**함.
        
        즉, `journalctl -u kube-apiserver` 같은 명령어로 로그를 보려고 하면 안 나오고, 직접 `/var/log/kube-apiserver.log` 파일을 열어서 봐야 함.
        

### 2) 쿠버네티스의 저장 매커니즘을 이용한 영구적인 로그 저장 공간 연결

- 쿠버네티스에서는 **파드 내부의 파일 시스템은 기본적으로 휘발성(volatile)이라서, 컨테이너가 재시작되면 로그가 사라질 수 있음**
- 하지만 **Persistent Volume (PV)이나 HostPath 볼륨을 사용해서 로그를 영구적으로 저장할 수 있음**
- 영구적인 저장 공간을 연결하는 방법
    - **HostPath 볼륨을 사용하여 `/var/log`에 로그를 기록**
        - 컨테이너 내부 `/var/log/`를 호스트의 `/var/log/` 디렉터리에 마운트하면, 컨테이너가 재시작되더라도 로그가 유지됨
    - **Persistent Volume (PV)와 Persistent Volume Claim (PVC)를 사용**
        - 특정한 스토리지(예: NFS, AWS EBS, Ceph 등)에 로그를 기록하면 컨테이너가 재시작되더라도 로그가 유지됨.
    
    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: log-pod
    spec:
      containers:
        - name: my-container
          image: busybox
          command: [ "sh", "-c", "while true; do echo $(date) 'Logging some data...' >> /var/log/app-logs/log.txt; sleep 5; done" ]
          volumeMounts:
            - mountPath: /var/log/app-logs  # 컨테이너 내부 경로
              name: log-storage
      volumes:
        - name: log-storage
          hostPath:
            path: /var/log/my-app  # 호스트 머신의 경로
            type: DirectoryOrCreate  # 없으면 자동 생성
    
    ```
    
- 비교) 쿠버네티스 기본 로깅 방식 (표준 출력 리디렉션)과 HostPath 볼륨 마운트와의 차이점
    - 애플리케이션이 `stdout`과 `stderr`에만 로그를 남기면 쿠버네티스가 자동으로 로그를 관리해줌.
    - 반면, HostPath 볼륨을 사용할 때는 로그가 `stdout`이 아니라 파일로 저장됨.
    - 즉, 런타임이 자동으로 로그를 리디렉션하는 것이 아니라, 애플리케이션이 직접 특정 파일에 로그를 작성해야 함.

- 통합 모니터링에서 로그 수집 정책 바꾸는 이유
    - 시스템 로그는 기존 콘솔 로그에 남기고
    - 비즈니스 로그 처럼 민감한 정보는 노드에만 남기고자 함.

### 3) 클러스터-레벨 로깅 아키텍처

- 쿠버네티스는 클러스터-레벨 로깅을 위한 네이티브 솔루션을 제공하지 않음.
- 대신 고려할만한 몇가지 일반적인 접근 방법이 있음
    1. 모든 노드에서 실행되는 노드-레벨 로깅 에이전트를 사용한다.
    2. 애플리케이션 파드에 로깅을 위한 전용 사이드카 컨테이너를 포함한다.
    3. 애플리케이션 내에서 로그를 백엔드로 직접 푸시한다.

1. **노드 로깅 에이전트 사용 (통합 모니터링에서 이 방법으로 클러스터 레벨의 로그 수집 중)**
    <img width="620" alt="image" src="https://github.com/user-attachments/assets/cf62cabd-174d-40fe-b0cf-6023031873a7" />

- 각 노드에 노드-레벨 로깅 에이전트를 포함시킴
- 로깅 에이전트는 로그를 백앤드로 푸시하는 전용 도구
- 데몬셋으로 배포되는 Elastic agent가 이 역할을 한다.
- 일반적으로 로깅 에이전트는 해당 노드의 모든 애플리케이션 컨테이너에서 로그 파일이 있는 디렉터리에 접근할 수 있는 권한을 갖는다.

1. 로깅 에이전트와 함께 사이드카 컨테이너 사용
    
    2-1. 사이드카 컨테이너 스트리밍 (사이드카 컨테이너가 애플리케이션 로그를 자체 `stdout` 으로 스트리밍)
    <img width="620" alt="image" src="https://github.com/user-attachments/assets/e30b15d3-a342-4e28-9077-c1440d924199" />

    
    2-2. 로깅 에이전트가 있는 사이드카 컨테이너
    <img width="620" alt="image" src="https://github.com/user-attachments/assets/c3d13680-64f9-4c67-8b63-623b09626e88" />


참고:

https://kubernetes.io/ko/docs/concepts/cluster-administration/logging/
